{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7983ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from pipeline import AnomalyDetectionPipeline, load_model, plot_lob_snapshot\n",
    "import preprocessing as prep\n",
    "import machine_learning as ml\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eed8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_attribution(attributions, feature_names, title=\"Feature Importance\", top_k=20):\n",
    "    \"\"\"\n",
    "    Aggregates attribution over time (sum or mean) and plots top k features.\n",
    "    Attributions shape: (1, Seq_Len, Feat)\n",
    "    \"\"\"\n",
    "    # Sum absolute attributions over time\n",
    "    # We want to know which feature contributed most overall\n",
    "    attr_sum = np.sum(np.abs(attributions), axis=(0, 1))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_attr = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Attribution': attr_sum\n",
    "    }).sort_values(by='Attribution', ascending=False).head(top_k)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df_attr, x='Attribution', y='Feature', hue='Feature', palette='viridis', legend=False)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Integrated Gradients Magnitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return df_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9493ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "# Select model\n",
    "DATASET = 'TOTF'\n",
    "MODEL = 'prae'\n",
    "SCALER = 'box-cox'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {DEVICE}\")\n",
    "\n",
    "config_path = f\"models/{DATASET}_{SCALER}_{MODEL}_config.json\"\n",
    "weights_path = f\"models/{DATASET}_{SCALER}_{MODEL}_weights.pth\"\n",
    "scaler_path = f\"models/{DATASET}_{SCALER}_{MODEL}_scaler.pkl\"\n",
    "conf = config.DATASETS[DATASET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42226b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline initialized on device: cuda\n",
      "Loading data from data/TOTF.PA-book/2015-01-02-TOTF.PA-book.csv.gz...\n",
      "Successfully loaded 640429 rows.\n",
      "Engineering features: ['base', 'tao', 'hawkes', 'poutre', 'ofi']...\n",
      "Feature Engineering complete. Total features: 130\n",
      "Preprocessing with method: box-cox...\n",
      "Dropping 2 constant/zero-variance features: ['ask_sweep_cost', 'ask-volume-10']\n",
      "Data split: Train 448300, Val 96064, Test 96065\n"
     ]
    }
   ],
   "source": [
    "# Initialize pipeline\n",
    "setup_pipeline = AnomalyDetectionPipeline()\n",
    "\n",
    "# Load data\n",
    "if DATASET == 'TOTF': setup_pipeline.load_data(conf['path'])\n",
    "elif DATASET == 'LOBSTER': setup_pipeline.raw_df = prep.load_lobster_data(conf['orderbook'], conf['message'])\n",
    "\n",
    "# Engineer features\n",
    "setup_pipeline.engineer_features(feature_sets=['base', 'tao', 'hawkes', 'poutre', 'ofi'])\n",
    "\n",
    "# Scale and sequence data\n",
    "setup_pipeline.scale_and_sequence(method='box-cox', train_ratio=0.7)\n",
    "\n",
    "# Match training logic for test set\n",
    "test_start_idx = int(len(setup_pipeline.processed_df) * 0.85)\n",
    "test_df = setup_pipeline.processed_df.iloc[test_start_idx:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4699d550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline initialized on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "pipeline, cfg = load_model(config_path, test_df, setup_pipeline.feature_names)\n",
    "\n",
    "state_dict = torch.load(weights_path, map_location=pipeline.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db3b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores = pipeline.predict(pipeline.X_test)\n",
    "threshold = np.percentile(anomaly_scores, 99)\n",
    "anomaly_indices = np.where(anomaly_scores > threshold)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c8712c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Anomaly at Index: 94933\n",
      "x_seq shape: torch.Size([1, 25, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adoni\\AppData\\Local\\Temp\\ipykernel_5176\\2774499043.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_seq = torch.tensor(raw_seq, dtype=torch.float32).unsqueeze(0).to(pipeline.device)\n"
     ]
    }
   ],
   "source": [
    "target_idx = anomaly_indices[0]\n",
    "print(f\"Analyzing Anomaly at Index: {target_idx}\")\n",
    "\n",
    "raw_seq = pipeline.X_test[target_idx][0]\n",
    "x_seq = torch.tensor(raw_seq, dtype=torch.float32).unsqueeze(0).to(pipeline.device)\n",
    "print(f\"x_seq shape: {x_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd4dad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenWrapper(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps PNN to accept (Batch, Seq, Feat) input by flattening it internally.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (Batch, Seq, Feat)\n",
    "        # Flatten to: (Batch, Seq * Feat)\n",
    "        batch_size = x.size(0)\n",
    "        x_flat = x.reshape(batch_size, -1)\n",
    "        return self.model(x_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013e7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pipeline.model_type == 'pnn':\n",
    "    model_to_explain = FlattenWrapper(pipeline.model)\n",
    "    target_fn = ml.pnn_uncertainty\n",
    "else:\n",
    "    model_to_explain = pipeline.model\n",
    "    \n",
    "    if pipeline.model_type == 'transformer_ocsvm': target_fn = ml.transformer_reconstruction_loss\n",
    "    elif pipeline.model_type == 'prae': target_fn = ml.prae_anomaly_score_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03771dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adoni\\AppData\\Local\\Temp\\ipykernel_5176\\3114895945.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_seq_tensor = torch.tensor(x_seq).unsqueeze(0).to(pipeline.device) # Shape: (1, 25, 14)\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "IG = ml.IntegratedGradients(pipeline.model)\n",
    "x_seq_tensor = torch.tensor(x_seq).unsqueeze(0).to(pipeline.device) # Shape: (1, 25, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2edd4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run IG with selected target function\n",
    "attrs = IG.attribute(\n",
    "    inputs=x_seq_tensor,\n",
    "    target_func=target_fn,\n",
    "    n_steps=50\n",
    ")\n",
    "\n",
    "attrs_np = attrs.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d82ed0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m top_features \u001b[38;5;241m=\u001b[39m \u001b[43mplot_feature_attribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattrs_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeature Importance for \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m on \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATASET\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m top_5_indices \u001b[38;5;241m=\u001b[39m [pipeline\u001b[38;5;241m.\u001b[39mfeature_names\u001b[38;5;241m.\u001b[39mindex(feat) \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m top_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[0;32m      4\u001b[0m top_5_names \u001b[38;5;241m=\u001b[39m top_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m, in \u001b[0;36mplot_feature_attribution\u001b[1;34m(attributions, feature_names, title, top_k)\u001b[0m\n\u001b[0;32m      8\u001b[0m attr_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mabs(attributions), axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df_attr \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAttribution\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_sum\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttribution\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(top_k)\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     17\u001b[0m sns\u001b[38;5;241m.\u001b[39mbarplot(data\u001b[38;5;241m=\u001b[39mdf_attr, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttribution\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m, palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m, legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\adoni\\Desktop\\Projet MDS\\MDS-Market_Manipulation\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    776\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    777\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    778\u001b[0m     )\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 782\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\adoni\\Desktop\\Projet MDS\\MDS-Market_Manipulation\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adoni\\Desktop\\Projet MDS\\MDS-Market_Manipulation\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\adoni\\Desktop\\Projet MDS\\MDS-Market_Manipulation\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "top_features = plot_feature_attribution(attrs_np, pipeline.feature_names, title=f\"Feature Importance for {MODEL.upper()} on {DATASET}\")\n",
    "\n",
    "top_5_indices = [pipeline.feature_names.index(feat) for feat in top_features['Feature'].head(5).values]\n",
    "top_5_names = top_features['Feature'].head(5).values\n",
    "\n",
    "heatmap_data = attrs_np[0, :, top_5_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, cmap=\"RdBu_r\", center=0, yticklabels=top_5_names)\n",
    "plt.title(f\"Temporal Feature Attribution for Top 5 Features - {MODEL.upper()} on {DATASET}\")\n",
    "plt.xlabel(\"Time Steps (Sequence)\")\n",
    "plt.show()\n",
    "\n",
    "plot_lob_snapshot(pipeline, target_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
