{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d037dc",
   "metadata": {},
   "source": [
    "# Sequential Training Pipeline\n",
    "\n",
    "Train models sequentially across multiple days:\n",
    "- **Dataset**: TOTF\n",
    "- **Scaler**: Box-Cox\n",
    "- **Models**: Transformer+OCSVM, PRAE, PNN\n",
    "- **Training Strategy**: Train on first hour of each day (5-min blocks), test on rest of day\n",
    "- **Final Test**: Final Day (25) (morning + rest of day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70488f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import preprocessing as prep\n",
    "import machine_learning as ml\n",
    "from pipeline import AnomalyDetectionPipeline, sequential_training_pipeline, plot_sequential_results\n",
    "\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509aeca",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Configuration\n",
    "DATA_DIR = 'data/TOTF.PA-book'  # Directory with daily TOTF files\n",
    "SCALER_TYPE = 'box-cox'\n",
    "\n",
    "# Sequential Training Parameters\n",
    "NUM_DAYS = 30  # Train on first 30 days\n",
    "FIRST_HOUR_MINUTES = 60  # Use first hour of each day\n",
    "TRAIN_BLOCK_MINUTES = 5  # 5-minute training blocks\n",
    "VAL_BLOCK_MINUTES = 5    # 5-minute validation blocks\n",
    "\n",
    "# Model Hyperparameters\n",
    "SEQ_LENGTH = 25\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5  # Fewer epochs per block for incremental training\n",
    "HIDDEN_DIM = 64\n",
    "LR = 1e-3\n",
    "PATIENCE = 3\n",
    "\n",
    "# Model Types to Train\n",
    "MODELS = ['transformer_ocsvm', 'prae', 'pnn']\n",
    "\n",
    "# Feature Sets\n",
    "FEATURE_SETS = ['base', 'tao', 'poutre', 'hawkes', 'ofi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12ff49",
   "metadata": {},
   "source": [
    "## Check Available Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available files\n",
    "files = sorted([f for f in os.listdir(DATA_DIR) if f.endswith(('.csv', '.csv.gz', '.parquet'))])\n",
    "print(f\"Found {len(files)} data files in {DATA_DIR}\")\n",
    "print(f\"\\nFirst 5 files:\")\n",
    "for f in files[:5]:\n",
    "    print(f\"  - {f}\")\n",
    "print(f\"\\nLast 5 files:\")\n",
    "for f in files[-5:]:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "if len(files) < NUM_DAYS + 1:\n",
    "    print(f\"\\nWARNING: Need at least {NUM_DAYS + 1} files for training. Found {len(files)}.\")\n",
    "    print(f\"Adjusting NUM_DAYS to {len(files) - 1}\")\n",
    "    NUM_DAYS = max(1, len(files) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36fad85",
   "metadata": {},
   "source": [
    "## Train Models Sequentially\n",
    "\n",
    "Train each model type on 30 days, evaluate on rest of each day + Day 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c789243",
   "metadata": {},
   "source": [
    "### 1. Transformer + OC-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa28ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAINING: Transformer + OC-SVM\")\n",
    "\n",
    "results_transformer, pipeline_transformer = sequential_training_pipeline(\n",
    "    data_dir=DATA_DIR,\n",
    "    num_days=NUM_DAYS,\n",
    "    first_hour_minutes=FIRST_HOUR_MINUTES,\n",
    "    train_block_minutes=TRAIN_BLOCK_MINUTES,\n",
    "    val_block_minutes=VAL_BLOCK_MINUTES,\n",
    "    model_type='transformer_ocsvm',\n",
    "    feature_sets=FEATURE_SETS,\n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    nu=0.01,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    patience=PATIENCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Save results\n",
    "with open('models/TOTF_sequential_transformer_ocsvm_results.json', 'w') as f:\n",
    "    json.dump(results_transformer, f, indent=2)\n",
    "\n",
    "# Save trained model\n",
    "base_filename = f\"models/TOTF_{SCALER_TYPE}_transformer_ocsvm_sequential\"\n",
    "torch.save(pipeline_transformer.model.state_dict(), f\"{base_filename}_weights.pth\")\n",
    "joblib.dump(pipeline_transformer.scaler, f\"{base_filename}_scaler.pkl\")\n",
    "if pipeline_transformer.detector is not None:\n",
    "    joblib.dump(pipeline_transformer.detector, f\"{base_filename}_ocsvm_detector.pkl\")\n",
    "    joblib.dump(pipeline_transformer.latent_scaler, f\"{base_filename}_latent_scaler.pkl\")\n",
    "\n",
    "config = {\n",
    "    'dataset': 'TOTF',\n",
    "    'model_type': 'transformer_ocsvm',\n",
    "    'scaler_type': SCALER_TYPE,\n",
    "    'training_type': 'sequential',\n",
    "    'num_days': NUM_DAYS,\n",
    "    'seq_length': SEQ_LENGTH,\n",
    "    'hidden_dim': HIDDEN_DIM,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'feature_names': pipeline_transformer.feature_names\n",
    "}\n",
    "with open(f\"{base_filename}_config.json\", 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved Transformer+OCSVM model to {base_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711b7cb",
   "metadata": {},
   "source": [
    "### 2. Probabilistic Robust Autoencoder (PRAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571cdb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAINING: PRAE\")\n",
    "\n",
    "results_prae, pipeline_prae = sequential_training_pipeline(\n",
    "    data_dir=DATA_DIR,\n",
    "    num_days=NUM_DAYS,\n",
    "    first_hour_minutes=FIRST_HOUR_MINUTES,\n",
    "    train_block_minutes=TRAIN_BLOCK_MINUTES,\n",
    "    val_block_minutes=VAL_BLOCK_MINUTES,\n",
    "    model_type='prae',\n",
    "    feature_sets=FEATURE_SETS,\n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    lambda_reg=0.1,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    patience=PATIENCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Save results\n",
    "with open('models/TOTF_sequential_prae_results.json', 'w') as f:\n",
    "    json.dump(results_prae, f, indent=2)\n",
    "\n",
    "# Save trained model\n",
    "base_filename = f\"models/TOTF_{SCALER_TYPE}_prae_sequential\"\n",
    "torch.save(pipeline_prae.model.state_dict(), f\"{base_filename}_weights.pth\")\n",
    "joblib.dump(pipeline_prae.scaler, f\"{base_filename}_scaler.pkl\")\n",
    "\n",
    "config = {\n",
    "    'dataset': 'TOTF',\n",
    "    'model_type': 'prae',\n",
    "    'scaler_type': SCALER_TYPE,\n",
    "    'training_type': 'sequential',\n",
    "    'num_days': NUM_DAYS,\n",
    "    'seq_length': SEQ_LENGTH,\n",
    "    'hidden_dim': HIDDEN_DIM,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'feature_names': pipeline_prae.feature_names\n",
    "}\n",
    "with open(f\"{base_filename}_config.json\", 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved PRAE model to {base_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48958a62",
   "metadata": {},
   "source": [
    "### 3. Probabilistic Neural Network (PNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAINING: PNN\")\n",
    "\n",
    "results_pnn, pipeline_pnn = sequential_training_pipeline(\n",
    "    data_dir=DATA_DIR,\n",
    "    num_days=NUM_DAYS,\n",
    "    first_hour_minutes=FIRST_HOUR_MINUTES,\n",
    "    train_block_minutes=TRAIN_BLOCK_MINUTES,\n",
    "    val_block_minutes=VAL_BLOCK_MINUTES,\n",
    "    model_type='pnn',\n",
    "    feature_sets=FEATURE_SETS,\n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    patience=PATIENCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Save results\n",
    "with open('models/TOTF_sequential_pnn_results.json', 'w') as f:\n",
    "    json.dump(results_pnn, f, indent=2)\n",
    "\n",
    "# Save trained model\n",
    "base_filename = f\"models/TOTF_{SCALER_TYPE}_pnn_sequential\"\n",
    "torch.save(pipeline_pnn.model.state_dict(), f\"{base_filename}_weights.pth\")\n",
    "joblib.dump(pipeline_pnn.scaler, f\"{base_filename}_scaler.pkl\")\n",
    "\n",
    "config = {\n",
    "    'dataset': 'TOTF',\n",
    "    'model_type': 'pnn',\n",
    "    'scaler_type': SCALER_TYPE,\n",
    "    'training_type': 'sequential',\n",
    "    'num_days': NUM_DAYS,\n",
    "    'seq_length': SEQ_LENGTH,\n",
    "    'hidden_dim': HIDDEN_DIM,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'feature_names': pipeline_pnn.feature_names\n",
    "}\n",
    "with open(f\"{base_filename}_config.json\", 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved PNN model to {base_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f0cee2",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6ca3e",
   "metadata": {},
   "source": [
    "### Transformer + OC-SVM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sequential_results(results_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e67e47",
   "metadata": {},
   "source": [
    "### PRAE Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sequential_results(results_prae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b119480",
   "metadata": {},
   "source": [
    "### PNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sequential_results(results_pnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c5e25",
   "metadata": {},
   "source": [
    "## Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "\n",
    "for model_name, results in [('Transformer+OCSVM', results_transformer), \n",
    "                             ('PRAE', results_prae), \n",
    "                             ('PNN', results_pnn)]:\n",
    "    \n",
    "    # Average over all training days\n",
    "    daily_df = pd.DataFrame(results['daily_metrics'])\n",
    "    avg_metrics = {\n",
    "        'Model': model_name,\n",
    "        'Avg_AUROC': daily_df['AUROC'].mean(),\n",
    "        'Avg_AUPRC': daily_df['AUPRC'].mean(),\n",
    "        'Avg_F4': daily_df['F4_Score'].mean(),\n",
    "    }\n",
    "    \n",
    "    # Final Day Morning\n",
    "    if results['final_day_morning_metrics']:\n",
    "        avg_metrics['FinalDay_Morning_AUROC'] = results['final_day_morning_metrics']['AUROC']\n",
    "        avg_metrics['FinalDay_Morning_AUPRC'] = results['final_day_morning_metrics']['AUPRC']\n",
    "        avg_metrics['FinalDay_Morning_F4'] = results['final_day_morning_metrics']['F4_Score']\n",
    "    \n",
    "    # Final Day Rest\n",
    "    if results['final_day_rest_metrics']:\n",
    "        avg_metrics['FinalDay_Rest_AUROC'] = results['final_day_rest_metrics']['AUROC']\n",
    "        avg_metrics['FinalDay_Rest_AUPRC'] = results['final_day_rest_metrics']['AUPRC']\n",
    "        avg_metrics['FinalDay_Rest_F4'] = results['final_day_rest_metrics']['F4_Score']\n",
    "    \n",
    "    comparison_data.append(avg_metrics)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"MODEL COMPARISON - Sequential Training\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('models/TOTF_sequential_model_comparison.csv', index=False)\n",
    "print(\"\\nSaved comparison to models/TOTF_sequential_model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3b14b",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04841081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SEQUENTIAL TRAINING SUMMARY\")\n",
    "print(f\"Dataset: TOTF\")\n",
    "print(f\"Scaler: {SCALER_TYPE}\")\n",
    "print(f\"Training Days: {NUM_DAYS}\")\n",
    "print(f\"Training Strategy: First {FIRST_HOUR_MINUTES} minutes per day\")\n",
    "print(f\"  - Train blocks: {TRAIN_BLOCK_MINUTES} minutes\")\n",
    "print(f\"  - Val blocks: {VAL_BLOCK_MINUTES} minutes\")\n",
    "print(f\"Test: Rest of each day + Final Day (morning & rest)\")\n",
    "print(\"\\nHyperparameters:\")\n",
    "print(f\"  - Sequence Length: {SEQ_LENGTH}\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Epochs per block: {EPOCHS}\")\n",
    "print(f\"  - Hidden Dim: {HIDDEN_DIM}\")\n",
    "print(f\"  - Learning Rate: {LR}\")\n",
    "print(\"\\nBest Model (by Final Day Rest AUROC):\")\n",
    "best_idx = comparison_df['FinalDay_Rest_AUROC'].idxmax()\n",
    "best_model = comparison_df.loc[best_idx]\n",
    "print(f\"  {best_model['Model']}\")\n",
    "print(f\"  - AUROC: {best_model['FinalDay_Rest_AUROC']:.4f}\")\n",
    "print(f\"  - AUPRC: {best_model['FinalDay_Rest_AUPRC']:.4f}\")\n",
    "print(f\"  - F4 Score: {best_model['FinalDay_Rest_F4']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
